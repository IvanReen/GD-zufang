2018-09-25 19:24:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: cw_zufang_slave)
2018-09-25 19:24:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Linux-4.15.0-33-generic-x86_64-with-Ubuntu-16.04-xenial
2018-09-25 19:45:54 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: cw_zufang_slave)
2018-09-25 19:45:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Linux-4.15.0-33-generic-x86_64-with-Ubuntu-16.04-xenial
2018-09-25 19:46:44 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: cw_zufang_slave)
2018-09-25 19:46:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Linux-4.15.0-33-generic-x86_64-with-Ubuntu-16.04-xenial
2018-09-25 19:51:45 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: cw_zufang_slave)
2018-09-25 19:51:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Linux-4.15.0-33-generic-x86_64-with-Ubuntu-16.04-xenial
2018-09-25 19:51:45 [scrapy.crawler] INFO: Overridden settings: {'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'cw_zufang_slave/logs/cw_zufang.log', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'DOWNLOAD_DELAY': 5, 'NEWSPIDER_MODULE': 'cw_zufang.spiders', 'CONCURRENT_REQUESTS': 8, 'SPIDER_MODULES': ['cw_zufang_slave.spiders'], 'COOKIES_ENABLED': False, 'BOT_NAME': 'cw_zufang_slave'}
2018-09-25 19:51:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-09-25 19:51:45 [cwzufang] INFO: Reading start URLs from redis key 'cwzufang_cw:requests' (batch size: 8, encoding: utf-8
2018-09-25 19:51:45 [py.warnings] WARNING: /home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2018-09-25 19:51:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 139.199.182.250:8000
2018-09-25 19:51:45 [twisted] CRITICAL: Unhandled error in Deferred:
2018-09-25 19:51:45 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 171, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 79, in create_connection
    raise err
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 69, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/usr/lib/python3.5/http/client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "/usr/lib/python3.5/http/client.py", line 1151, in _send_request
    self.endheaders(body)
  File "/usr/lib/python3.5/http/client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "/usr/lib/python3.5/http/client.py", line 934, in _send_output
    self.send(msg)
  File "/usr/lib/python3.5/http/client.py", line 877, in send
    self.connect()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 196, in connect
    conn = self._new_conn()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 180, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fc750c16c18>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 445, in send
    timeout=timeout
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc750c16c18>: Failed to establish a new connection: [Errno 111] Connection refused',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 986, in _gcd_import
  File "<frozen importlib._bootstrap>", line 969, in _find_and_load
  File "<frozen importlib._bootstrap>", line 958, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 673, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 665, in exec_module
  File "<frozen importlib._bootstrap>", line 222, in _call_with_frames_removed
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/proxy_mw.py", line 4, in <module>
    from cw_zufang_slave.utils.GetProxyIp import GetIps
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 13, in <module>
    GetIps()
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 8, in GetIps
    ips=requests.get(url)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 512, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 622, in send
    r = adapter.send(request, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 513, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc750c16c18>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-09-25 19:51:51 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: cw_zufang_slave)
2018-09-25 19:51:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Linux-4.15.0-33-generic-x86_64-with-Ubuntu-16.04-xenial
2018-09-25 19:51:57 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: cw_zufang_slave)
2018-09-25 19:51:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Linux-4.15.0-33-generic-x86_64-with-Ubuntu-16.04-xenial
2018-09-25 19:52:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: cw_zufang_slave)
2018-09-25 19:52:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Linux-4.15.0-33-generic-x86_64-with-Ubuntu-16.04-xenial
2018-09-25 19:52:05 [scrapy.crawler] INFO: Overridden settings: {'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'ROBOTSTXT_OBEY': True, 'CONCURRENT_REQUESTS': 8, 'LOG_FILE': 'cw_zufang_slave/logs/cw_zufang.log', 'NEWSPIDER_MODULE': 'cw_zufang.spiders', 'BOT_NAME': 'cw_zufang_slave', 'DOWNLOAD_DELAY': 5, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'COOKIES_ENABLED': False, 'SPIDER_MODULES': ['cw_zufang_slave.spiders']}
2018-09-25 19:52:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-09-25 19:52:05 [cwzufang] INFO: Reading start URLs from redis key 'cwzufang_cw:requests' (batch size: 8, encoding: utf-8
2018-09-25 19:52:05 [py.warnings] WARNING: /home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2018-09-25 19:52:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 139.199.182.250:8000
2018-09-25 19:52:05 [twisted] CRITICAL: Unhandled error in Deferred:
2018-09-25 19:52:05 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 171, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 79, in create_connection
    raise err
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 69, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/usr/lib/python3.5/http/client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "/usr/lib/python3.5/http/client.py", line 1151, in _send_request
    self.endheaders(body)
  File "/usr/lib/python3.5/http/client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "/usr/lib/python3.5/http/client.py", line 934, in _send_output
    self.send(msg)
  File "/usr/lib/python3.5/http/client.py", line 877, in send
    self.connect()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 196, in connect
    conn = self._new_conn()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 180, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fa6358fabe0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 445, in send
    timeout=timeout
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa6358fabe0>: Failed to establish a new connection: [Errno 111] Connection refused',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 986, in _gcd_import
  File "<frozen importlib._bootstrap>", line 969, in _find_and_load
  File "<frozen importlib._bootstrap>", line 958, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 673, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 665, in exec_module
  File "<frozen importlib._bootstrap>", line 222, in _call_with_frames_removed
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/proxy_mw.py", line 4, in <module>
    from cw_zufang_slave.utils.GetProxyIp import GetIps
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 13, in <module>
    GetIps()
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 8, in GetIps
    ips=requests.get(url)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 512, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 622, in send
    r = adapter.send(request, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 513, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa6358fabe0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-09-25 19:53:55 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: cw_zufang_slave)
2018-09-25 19:53:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Linux-4.15.0-33-generic-x86_64-with-Ubuntu-16.04-xenial
2018-09-25 19:53:55 [scrapy.crawler] INFO: Overridden settings: {'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['cw_zufang_slave.spiders'], 'BOT_NAME': 'cw_zufang_slave', 'NEWSPIDER_MODULE': 'cw_zufang.spiders', 'CONCURRENT_REQUESTS': 8, 'LOG_FILE': 'cw_zufang_slave/logs/cw_zufang.log', 'COOKIES_ENABLED': False, 'ROBOTSTXT_OBEY': True, 'DOWNLOAD_DELAY': 5}
2018-09-25 19:53:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats']
2018-09-25 19:53:55 [cwzufang] INFO: Reading start URLs from redis key 'cwzufang_cw:requests' (batch size: 8, encoding: utf-8
2018-09-25 19:53:55 [py.warnings] WARNING: /home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2018-09-25 19:53:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 139.199.182.250:8000
2018-09-25 19:53:55 [twisted] CRITICAL: Unhandled error in Deferred:
2018-09-25 19:53:55 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 171, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 79, in create_connection
    raise err
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 69, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/usr/lib/python3.5/http/client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "/usr/lib/python3.5/http/client.py", line 1151, in _send_request
    self.endheaders(body)
  File "/usr/lib/python3.5/http/client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "/usr/lib/python3.5/http/client.py", line 934, in _send_output
    self.send(msg)
  File "/usr/lib/python3.5/http/client.py", line 877, in send
    self.connect()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 196, in connect
    conn = self._new_conn()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 180, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f0b17b41080>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 445, in send
    timeout=timeout
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0b17b41080>: Failed to establish a new connection: [Errno 111] Connection refused',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 986, in _gcd_import
  File "<frozen importlib._bootstrap>", line 969, in _find_and_load
  File "<frozen importlib._bootstrap>", line 958, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 673, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 665, in exec_module
  File "<frozen importlib._bootstrap>", line 222, in _call_with_frames_removed
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/proxy_mw.py", line 4, in <module>
    from cw_zufang_slave.utils.GetProxyIp import GetIps
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 13, in <module>
    GetIps()
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 8, in GetIps
    ips=requests.get(url)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 512, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 622, in send
    r = adapter.send(request, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 513, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f0b17b41080>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-09-25 19:55:25 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: cw_zufang_slave)
2018-09-25 19:55:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Linux-4.15.0-33-generic-x86_64-with-Ubuntu-16.04-xenial
2018-09-25 19:55:25 [scrapy.crawler] INFO: Overridden settings: {'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'cw_zufang_slave/logs/cw_zufang.log', 'DOWNLOAD_DELAY': 5, 'ROBOTSTXT_OBEY': True, 'CONCURRENT_REQUESTS': 8, 'COOKIES_ENABLED': False, 'BOT_NAME': 'cw_zufang_slave', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['cw_zufang_slave.spiders'], 'NEWSPIDER_MODULE': 'cw_zufang.spiders'}
2018-09-25 19:55:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.telnet.TelnetConsole']
2018-09-25 19:55:25 [cwzufang] INFO: Reading start URLs from redis key 'cwzufang_cw:requests' (batch size: 8, encoding: utf-8
2018-09-25 19:55:25 [py.warnings] WARNING: /home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2018-09-25 19:55:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 139.199.182.250:8000
2018-09-25 19:55:25 [twisted] CRITICAL: Unhandled error in Deferred:
2018-09-25 19:55:25 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 171, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 79, in create_connection
    raise err
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 69, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/usr/lib/python3.5/http/client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "/usr/lib/python3.5/http/client.py", line 1151, in _send_request
    self.endheaders(body)
  File "/usr/lib/python3.5/http/client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "/usr/lib/python3.5/http/client.py", line 934, in _send_output
    self.send(msg)
  File "/usr/lib/python3.5/http/client.py", line 877, in send
    self.connect()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 196, in connect
    conn = self._new_conn()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 180, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f487f13dbe0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 445, in send
    timeout=timeout
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f487f13dbe0>: Failed to establish a new connection: [Errno 111] Connection refused',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 986, in _gcd_import
  File "<frozen importlib._bootstrap>", line 969, in _find_and_load
  File "<frozen importlib._bootstrap>", line 958, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 673, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 665, in exec_module
  File "<frozen importlib._bootstrap>", line 222, in _call_with_frames_removed
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/proxy_mw.py", line 4, in <module>
    from cw_zufang_slave.utils.GetProxyIp import GetIps
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 13, in <module>
    GetIps()
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 8, in GetIps
    ips=requests.get(url)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 512, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 622, in send
    r = adapter.send(request, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 513, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f487f13dbe0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-09-25 19:55:27 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: cw_zufang_slave)
2018-09-25 19:55:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Linux-4.15.0-33-generic-x86_64-with-Ubuntu-16.04-xenial
2018-09-25 19:55:27 [scrapy.crawler] INFO: Overridden settings: {'ROBOTSTXT_OBEY': True, 'NEWSPIDER_MODULE': 'cw_zufang.spiders', 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'COOKIES_ENABLED': False, 'CONCURRENT_REQUESTS': 8, 'DOWNLOAD_DELAY': 5, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['cw_zufang_slave.spiders'], 'BOT_NAME': 'cw_zufang_slave', 'LOG_FILE': 'cw_zufang_slave/logs/cw_zufang.log'}
2018-09-25 19:55:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2018-09-25 19:55:27 [cwzufang] INFO: Reading start URLs from redis key 'cwzufang_cw:requests' (batch size: 8, encoding: utf-8
2018-09-25 19:55:27 [py.warnings] WARNING: /home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2018-09-25 19:55:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 139.199.182.250:8000
2018-09-25 19:55:27 [twisted] CRITICAL: Unhandled error in Deferred:
2018-09-25 19:55:27 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 171, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 79, in create_connection
    raise err
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 69, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/usr/lib/python3.5/http/client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "/usr/lib/python3.5/http/client.py", line 1151, in _send_request
    self.endheaders(body)
  File "/usr/lib/python3.5/http/client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "/usr/lib/python3.5/http/client.py", line 934, in _send_output
    self.send(msg)
  File "/usr/lib/python3.5/http/client.py", line 877, in send
    self.connect()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 196, in connect
    conn = self._new_conn()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 180, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fe00a218080>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 445, in send
    timeout=timeout
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe00a218080>: Failed to establish a new connection: [Errno 111] Connection refused',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 986, in _gcd_import
  File "<frozen importlib._bootstrap>", line 969, in _find_and_load
  File "<frozen importlib._bootstrap>", line 958, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 673, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 665, in exec_module
  File "<frozen importlib._bootstrap>", line 222, in _call_with_frames_removed
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/proxy_mw.py", line 4, in <module>
    from cw_zufang_slave.utils.GetProxyIp import GetIps
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 13, in <module>
    GetIps()
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 8, in GetIps
    ips=requests.get(url)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 512, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 622, in send
    r = adapter.send(request, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 513, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe00a218080>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-09-25 19:55:49 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: cw_zufang_slave)
2018-09-25 19:55:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Linux-4.15.0-33-generic-x86_64-with-Ubuntu-16.04-xenial
2018-09-25 19:55:49 [scrapy.crawler] INFO: Overridden settings: {'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'NEWSPIDER_MODULE': 'cw_zufang_slave.spiders', 'DOWNLOAD_DELAY': 5, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'cw_zufang_slave/logs/cw_zufang.log', 'COOKIES_ENABLED': False, 'SPIDER_MODULES': ['cw_zufang_slave.spiders'], 'CONCURRENT_REQUESTS': 8, 'BOT_NAME': 'cw_zufang_slave', 'ROBOTSTXT_OBEY': True}
2018-09-25 19:55:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-09-25 19:55:49 [cwzufang] INFO: Reading start URLs from redis key 'cwzufang_cw:requests' (batch size: 8, encoding: utf-8
2018-09-25 19:55:49 [py.warnings] WARNING: /home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2018-09-25 19:55:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 139.199.182.250:8000
2018-09-25 19:55:49 [twisted] CRITICAL: Unhandled error in Deferred:
2018-09-25 19:55:49 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 171, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 79, in create_connection
    raise err
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 69, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/usr/lib/python3.5/http/client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "/usr/lib/python3.5/http/client.py", line 1151, in _send_request
    self.endheaders(body)
  File "/usr/lib/python3.5/http/client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "/usr/lib/python3.5/http/client.py", line 934, in _send_output
    self.send(msg)
  File "/usr/lib/python3.5/http/client.py", line 877, in send
    self.connect()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 196, in connect
    conn = self._new_conn()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 180, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f10f08f7080>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 445, in send
    timeout=timeout
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f10f08f7080>: Failed to establish a new connection: [Errno 111] Connection refused',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 986, in _gcd_import
  File "<frozen importlib._bootstrap>", line 969, in _find_and_load
  File "<frozen importlib._bootstrap>", line 958, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 673, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 665, in exec_module
  File "<frozen importlib._bootstrap>", line 222, in _call_with_frames_removed
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/proxy_mw.py", line 4, in <module>
    from cw_zufang_slave.utils.GetProxyIp import GetIps
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 13, in <module>
    GetIps()
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 8, in GetIps
    ips=requests.get(url)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 512, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 622, in send
    r = adapter.send(request, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 513, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f10f08f7080>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-09-25 19:56:27 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: cw_zufang_slave)
2018-09-25 19:56:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Linux-4.15.0-33-generic-x86_64-with-Ubuntu-16.04-xenial
2018-09-25 19:56:28 [scrapy.crawler] INFO: Overridden settings: {'SPIDER_MODULES': ['cw_zufang_slave.spiders'], 'LOG_FILE': 'cw_zufang_slave/logs/cw_zufang.log', 'NEWSPIDER_MODULE': 'cw_zufang_slave.spiders', 'CONCURRENT_REQUESTS': 8, 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 5, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'BOT_NAME': 'cw_zufang_slave', 'ROBOTSTXT_OBEY': True}
2018-09-25 19:56:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage']
2018-09-25 19:56:28 [cwzufang] INFO: Reading start URLs from redis key 'cwzufang_cw:requests' (batch size: 8, encoding: utf-8
2018-09-25 19:56:28 [py.warnings] WARNING: /home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2018-09-25 19:56:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 139.199.182.250:8000
2018-09-25 19:56:28 [twisted] CRITICAL: Unhandled error in Deferred:
2018-09-25 19:56:28 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 171, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 79, in create_connection
    raise err
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 69, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/usr/lib/python3.5/http/client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "/usr/lib/python3.5/http/client.py", line 1151, in _send_request
    self.endheaders(body)
  File "/usr/lib/python3.5/http/client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "/usr/lib/python3.5/http/client.py", line 934, in _send_output
    self.send(msg)
  File "/usr/lib/python3.5/http/client.py", line 877, in send
    self.connect()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 196, in connect
    conn = self._new_conn()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 180, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fbe52927be0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 445, in send
    timeout=timeout
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fbe52927be0>: Failed to establish a new connection: [Errno 111] Connection refused',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 986, in _gcd_import
  File "<frozen importlib._bootstrap>", line 969, in _find_and_load
  File "<frozen importlib._bootstrap>", line 958, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 673, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 665, in exec_module
  File "<frozen importlib._bootstrap>", line 222, in _call_with_frames_removed
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/proxy_mw.py", line 4, in <module>
    from cw_zufang_slave.utils.GetProxyIp import GetIps
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 13, in <module>
    GetIps()
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 8, in GetIps
    ips=requests.get(url)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 512, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 622, in send
    r = adapter.send(request, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 513, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fbe52927be0>: Failed to establish a new connection: [Errno 111] Connection refused',))
2018-09-25 19:56:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: cw_zufang_slave)
2018-09-25 19:56:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.4.0, Python 3.5.2 (default, Nov 23 2017, 16:37:01) - [GCC 5.4.0 20160609], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.3, Platform Linux-4.15.0-33-generic-x86_64-with-Ubuntu-16.04-xenial
2018-09-25 19:56:56 [scrapy.crawler] INFO: Overridden settings: {'CONCURRENT_REQUESTS': 8, 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_MODULES': ['cw_zufang_slave.spiders'], 'NEWSPIDER_MODULE': 'cw_zufang_slave.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'COOKIES_ENABLED': False, 'LOG_FILE': 'cw_zufang_slave/logs/cw_zufang.log', 'DOWNLOAD_DELAY': 5, 'BOT_NAME': 'cw_zufang_slave'}
2018-09-25 19:56:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-09-25 19:56:57 [cwzufang] INFO: Reading start URLs from redis key 'cwzufang_cw:requests' (batch size: 8, encoding: utf-8
2018-09-25 19:56:57 [py.warnings] WARNING: /home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2018-09-25 19:56:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 139.199.182.250:8000
2018-09-25 19:56:57 [twisted] CRITICAL: Unhandled error in Deferred:
2018-09-25 19:56:57 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 171, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 79, in create_connection
    raise err
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/connection.py", line 69, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 354, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/usr/lib/python3.5/http/client.py", line 1106, in request
    self._send_request(method, url, body, headers)
  File "/usr/lib/python3.5/http/client.py", line 1151, in _send_request
    self.endheaders(body)
  File "/usr/lib/python3.5/http/client.py", line 1102, in endheaders
    self._send_output(message_body)
  File "/usr/lib/python3.5/http/client.py", line 934, in _send_output
    self.send(msg)
  File "/usr/lib/python3.5/http/client.py", line 877, in send
    self.connect()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 196, in connect
    conn = self._new_conn()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connection.py", line 180, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ff3536d2048>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 445, in send
    timeout=timeout
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/urllib3/util/retry.py", line 398, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ff3536d2048>: Failed to establish a new connection: [Errno 111] Connection refused',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/twisted/internet/defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 986, in _gcd_import
  File "<frozen importlib._bootstrap>", line 969, in _find_and_load
  File "<frozen importlib._bootstrap>", line 958, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 673, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 665, in exec_module
  File "<frozen importlib._bootstrap>", line 222, in _call_with_frames_removed
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/proxy_mw.py", line 4, in <module>
    from cw_zufang_slave.utils.GetProxyIp import GetIps
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 13, in <module>
    GetIps()
  File "/home/rcw/Downloads/GD-zufang/cw_zufang_slave/cw_zufang_slave/utils/GetProxyIp.py", line 8, in GetIps
    ips=requests.get(url)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 512, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/sessions.py", line 622, in send
    r = adapter.send(request, **kwargs)
  File "/home/rcw/.virtualenvs/zufang/lib/python3.5/site-packages/requests/adapters.py", line 513, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='139.199.182.250', port=8000): Max retries exceeded with url: /?types=0&count=300 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ff3536d2048>: Failed to establish a new connection: [Errno 111] Connection refused',))
